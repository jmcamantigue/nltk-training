{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-tensorflow-board.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "NKzW-fBI3vAb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkpHsENh36sU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-3_EjYT4DrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d011f10-1191-4211-e7bc-8590a534f9ec"
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y = load_iris().target\n",
        "\n",
        "x[:10], y[:10]\n",
        "np.unique(y)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "hauXJ_KW7ydF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_text, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTuOCnIG76NA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t56DHQz_73mf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('input'):\n",
        "  input_features = tf.placeholder(dtype=tf.float32, shape=[None, x.shape[1]], name='input_features')\n",
        "  input_labels = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='input_labels')\n",
        "  \n",
        "with tf.name_scope('model'):\n",
        "  weights = tf.Variable(tf.random_normal(shape=[x.shape[1], 3]), name='weights')\n",
        "  biases = tf.Variable(tf.random_normal(shape=[3]))\n",
        "  linear_model = tf.add(tf.matmul(input_features, weights), biases)\n",
        "  predictions = tf.nn.softmax(linear_model)\n",
        "\n",
        "with tf.name_scope('training_ops'):\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits=linear_model, labels=input_labels))\n",
        "  train_op = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
        "  tf.summary.scalar(name='loss', tensor=loss)\n",
        "  \n",
        "with tf.name_scope('metrics'):\n",
        "  correct_prediction = tf.cast(tf.equal(tf.argmax(predictions, 1),\n",
        "                                       tf.argmax(input_labels, 1)), tf.float32)\n",
        "  accuracy_op = tf.reduce_mean(correct_prediction)\n",
        "  tf.summary.scalar(name='accuracy', tensor=accuracy_op)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcLsGoQo_WA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start=0, stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iklhBzTsCZG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "aaad4ef8-df7b-4150-a67e-ecfffdf5c687"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf logs/\n",
        "!rm ngrok*\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-17 04:23:24--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.73.140.127, 52.72.251.164, 54.156.237.249, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.73.140.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-08-17 04:23:25 (43.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3A43-jo3Cy21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {0} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5xS9nUjDVer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8g98Mzp3DjrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b16748f4-252e-4c09-bc89-e00777c6e63a"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://e8445460.ngrok.io\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TwKShLgN-tbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7c966235-41a7-4085-c09e-1cbbb14e624a"
      },
      "cell_type": "code",
      "source": [
        "init_op = tf.global_variables_initializer()\n",
        "batch_size = 15\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  sess.run(init_op)\n",
        "  summary = tf.summary.merge_all()\n",
        "  writer = tf.summary.FileWriter(logdir='./logs', graph=tf.get_default_graph())\n",
        "\n",
        "  for epoch in range(10):\n",
        "    for index in range(int(x.shape[0]/batch_size)):\n",
        "      mini_batch_x, mini_batch_y= next_batch(batch_size=batch_size, features=x, labels=y)\n",
        "\n",
        "      _, train_loss = sess.run([train_op, loss], feed_dict={input_features: mini_batch_x, input_labels: mini_batch_y})\n",
        "\n",
        "    print('Epoch: {0}, loss : {1}'.format(epoch, train_loss))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss : 5.248170852661133\n",
            "Epoch: 1, loss : 7.680081367492676\n",
            "Epoch: 2, loss : 4.932286739349365\n",
            "Epoch: 3, loss : 4.876423358917236\n",
            "Epoch: 4, loss : 7.156226634979248\n",
            "Epoch: 5, loss : 3.299905300140381\n",
            "Epoch: 6, loss : 4.476098537445068\n",
            "Epoch: 7, loss : 7.7392048835754395\n",
            "Epoch: 8, loss : 5.140228271484375\n",
            "Epoch: 9, loss : 5.757898807525635\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}