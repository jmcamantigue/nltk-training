{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-logistic-regression.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "NKzW-fBI3vAb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkpHsENh36sU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-3_EjYT4DrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57ff0ce6-bef8-450a-d277-a5cb3e890f15"
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y = load_iris().target\n",
        "\n",
        "x[:10], y[:10]\n",
        "np.unique(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "VAarePKb4NpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# batch_size 4\n",
        "input_features = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
        "# batch size 3\n",
        "input_labels = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
        "# [4, 3]\n",
        "weights = tf.Variable(tf.random_normal(shape=[4, 3]))\n",
        "# [3]\n",
        "biases = tf.Variable(tf.random_normal(shape=[3]))\n",
        "# Construct model\n",
        "pred = tf.nn.softmax(tf.matmul(input_features, weights) + biases) # Softmax\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(input_labels*tf.log(pred), reduction_indices=1))\n",
        "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.002).minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M33QsvCv8SVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgQBUzdQ8VnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-X4BJo68brG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start=0, stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gGjz7dr1yla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "fdc4c1da-c3ff-42be-fe51-87c346aa5a35"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "\n",
        "batch_size = 15\n",
        "for epoch in range(50):\n",
        "  for index in range(int(x.shape[0]/batch_size)):\n",
        "    mini_batch_x, mini_batch_y = next_batch(batch_size=batch_size, features=x, labels=y)\n",
        "    \n",
        "    _, train_loss = sess.run([train_op, loss], feed_dict={input_features: mini_batch_x, input_labels: mini_batch_y})\n",
        "    \n",
        "  print('Epoch: {0}, loss : {1}'.format(epoch, train_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss : 7.690713405609131\n",
            "Epoch: 1, loss : 10.72579574584961\n",
            "Epoch: 2, loss : 4.75623083114624\n",
            "Epoch: 3, loss : 5.826510906219482\n",
            "Epoch: 4, loss : 7.065653324127197\n",
            "Epoch: 5, loss : 8.791947364807129\n",
            "Epoch: 6, loss : 8.225549697875977\n",
            "Epoch: 7, loss : 5.866566181182861\n",
            "Epoch: 8, loss : 6.135141372680664\n",
            "Epoch: 9, loss : 5.675791263580322\n",
            "Epoch: 10, loss : 4.400258541107178\n",
            "Epoch: 11, loss : 4.227076053619385\n",
            "Epoch: 12, loss : 4.628079414367676\n",
            "Epoch: 13, loss : 3.158766269683838\n",
            "Epoch: 14, loss : 3.2430715560913086\n",
            "Epoch: 15, loss : 2.7715694904327393\n",
            "Epoch: 16, loss : 2.6972854137420654\n",
            "Epoch: 17, loss : 1.9512735605239868\n",
            "Epoch: 18, loss : 2.0418570041656494\n",
            "Epoch: 19, loss : 2.17753267288208\n",
            "Epoch: 20, loss : 1.6870994567871094\n",
            "Epoch: 21, loss : 1.8177446126937866\n",
            "Epoch: 22, loss : 1.8942822217941284\n",
            "Epoch: 23, loss : 1.7218910455703735\n",
            "Epoch: 24, loss : 1.8281916379928589\n",
            "Epoch: 25, loss : 2.0287630558013916\n",
            "Epoch: 26, loss : 1.985666036605835\n",
            "Epoch: 27, loss : 1.6261061429977417\n",
            "Epoch: 28, loss : 2.417313575744629\n",
            "Epoch: 29, loss : 1.9386848211288452\n",
            "Epoch: 30, loss : 2.1188743114471436\n",
            "Epoch: 31, loss : 1.9572163820266724\n",
            "Epoch: 32, loss : 1.879967212677002\n",
            "Epoch: 33, loss : 2.1765685081481934\n",
            "Epoch: 34, loss : 1.5764784812927246\n",
            "Epoch: 35, loss : 1.546929121017456\n",
            "Epoch: 36, loss : 1.9139888286590576\n",
            "Epoch: 37, loss : 1.375244379043579\n",
            "Epoch: 38, loss : 1.8562815189361572\n",
            "Epoch: 39, loss : 1.981793999671936\n",
            "Epoch: 40, loss : 1.4383405447006226\n",
            "Epoch: 41, loss : 1.5473953485488892\n",
            "Epoch: 42, loss : 1.4590057134628296\n",
            "Epoch: 43, loss : 1.5522278547286987\n",
            "Epoch: 44, loss : 1.4752205610275269\n",
            "Epoch: 45, loss : 1.618058443069458\n",
            "Epoch: 46, loss : 1.7070096731185913\n",
            "Epoch: 47, loss : 1.9484621286392212\n",
            "Epoch: 48, loss : 1.3238327503204346\n",
            "Epoch: 49, loss : 1.5702797174453735\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}