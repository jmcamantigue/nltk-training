{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-logistic-regression-ngrams.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aQLNbVJcQMiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code for TensorBoard\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "VkaMehYdIwIQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "223cc885-baf0-4305-a8e1-cca14d78022c"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf logs/\n",
        "!rm ngrok*\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47plbab5I2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcq21uFLI9ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inqmnVzbJD1h",
        "colab_type": "code",
        "colab": {},
        "outputId": "45e928a5-c70c-4184-fbf5-cd16e755d91c"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Bh_PVLdQS4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code for Downloading data from Google Drive\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "IZK7c1IwPXme",
        "colab_type": "code",
        "colab": {},
        "outputId": "0c4ee246-b346-4f6d-fada-f7f167ea6f77"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'13sCOigbP_BO5XdpbLn7o0jLQY3sDWZEs' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OfpqBtTQZA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preparing the Dataset\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "G0f7tNdgIyyN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ss6xttoF7hkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./data/reviews.txt', 'r') as file:\n",
        "  features = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoDv7SrAPjCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = features.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ej2p7FQeQepm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting trigrams"
      ]
    },
    {
      "metadata": {
        "id": "qBVEXKrW7u9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8GuWk817zDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vectorizer(text):\n",
        "  vec = CountVectorizer(binary=True, min_df=3, ngram_range=(3, 3), token_pattern='(?u)\\\\b[a-z0-9\\-\\_]{3,}\\\\b', stop_words='english')\n",
        "  vec.fit(text)\n",
        "  return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-OYHI7L5VgKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec = vectorizer(features)\n",
        "ngrams = vec.transform(features).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9j2BFFG79Wf",
        "colab_type": "code",
        "colab": {},
        "outputId": "4bb4b513-fe4a-48f8-ee8e-8b010cf02793"
      },
      "cell_type": "code",
      "source": [
        "ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFMNl8_XP08x",
        "colab_type": "code",
        "colab": {},
        "outputId": "e57e2b31-0fe1-41df-c16a-3b8547bea7d4"
      },
      "cell_type": "code",
      "source": [
        "ngrams.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB-UuJMFQivM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One-hot encoding the labels"
      ]
    },
    {
      "metadata": {
        "id": "unAcktV5P11x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./data/labels.txt', 'r') as file:\n",
        "  labels = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaGtq7biP9uN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = np.array([1 if label == 'positive' else 0 for label in labels.split('\\n')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6aQcyj2OQEbA",
        "colab_type": "code",
        "colab": {},
        "outputId": "a41eb59e-56cc-458d-cb3f-1b6e3fb94a5c"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIAzufoWQGko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkF2GcB1QnPI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the dataset"
      ]
    },
    {
      "metadata": {
        "id": "OyZefu_VQJ4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(ngrams, labels[0:25000], test_size=0.30, stratify=labels[0:25000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T5LHtvCNRC8H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Building the Model\n",
        "==="
      ]
    },
    {
      "metadata": {
        "id": "HBZjZW-Z8E4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0CqLQEA8HWs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.name_scope('input'):\n",
        "  input_features = tf.placeholder(dtype=tf.float32, shape=[None, ngrams.shape[1]],\n",
        "                                 name='input_features')\n",
        "  input_labels = tf.placeholder(dtype=tf.float32, shape=[None, labels.shape[1]],\n",
        "                               name='input_labels')\n",
        "\n",
        "  with tf.name_scope('model'):\n",
        "    weights = tf.Variable(tf.random_normal(shape=[ngrams.shape[1], labels.shape[1]]),\n",
        "                          name='weights')\n",
        "    biases = tf.Variable(tf.random_normal(shape=[labels.shape[1]]))\n",
        "    linear_model = tf.add(tf.matmul(input_features, weights), biases)\n",
        "    predictions = tf.nn.softmax(linear_model)\n",
        "    \n",
        "with tf.name_scope('training_ops'):\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "      logits=linear_model, labels=input_labels))\n",
        "  train_op = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(loss)\n",
        "  tf.summary.scalar(name='loss', tensor=loss)\n",
        "\n",
        "with tf.name_scope('metrics'):\n",
        "  correct_prediction = tf.cast(tf.equal(tf.argmax(predictions, 1),\n",
        "                                         tf.argmax(input_labels, 1)), tf.float32)\n",
        "  accuracy_op = tf.reduce_mean(correct_prediction)\n",
        "  tf.summary.scalar(name='accuracy', tensor=accuracy_op)\n",
        "\n",
        "summary = tf.summary.merge_all()\n",
        "writer = tf.summary.FileWriter(logdir='logs', graph=tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gS1pF5ir-nL_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6WWWGO9-3Sy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start=0, stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8VSK1NN-rPx",
        "colab_type": "code",
        "colab": {},
        "outputId": "df4be207-cb8a-4a73-f385-a578f7fd29cb"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "  \n",
        "  # epochs = 10\n",
        "  for epoch in range(10):\n",
        "    for mini_batch in range(int(x_train.shape[0] / 16)):\n",
        "      batch_x, batch_y = next_batch(batch_size=16, features=x_train, labels=y_train)\n",
        "      \n",
        "      _, train_loss, train_accuracy, train_summary = sess.run([train_op, loss,\n",
        "                                                               accuracy_op,\n",
        "                                                              summary],\n",
        "                                              feed_dict={input_features: batch_x,\n",
        "                                                        input_labels: batch_y})\n",
        "      writer.add_summary(summary=train_summary, global_step=mini_batch)\n",
        "    print('Epoch {}, loss : {}, accuracy : {}'.format(epoch, train_loss,\n",
        "                                                      train_accuracy))  \n",
        "  \n",
        "  test_accuracy = sess.run(accuracy_op, feed_dict={input_features: x_test, input_labels: y_test})\n",
        "  print('Test accuracy : {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQx28Ab_NdnU",
        "colab_type": "code",
        "colab": {},
        "outputId": "3a27929d-0f71-409e-d84e-af4f74e8b07c"
      },
      "cell_type": "code",
      "source": [
        "classes = ['Negative', 'Positive']\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "  prediction_ = sess.run(predictions, feed_dict={input_features: x_test[1].reshape(-1, x_test.shape[1])})\n",
        "  print(prediction_)\n",
        "  print('predicted class : {}, true class : {}'.format(sess.run(tf.argmax(prediction_, 1)), classes[sess.run(tf.argmax(y_test[1]))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDJfrmONUaMe",
        "colab_type": "code",
        "colab": {},
        "outputId": "8280248a-1977-4c62-94bd-23c0415b947f"
      },
      "cell_type": "code",
      "source": [
        "features[100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bQ7wJOfUg2B",
        "colab_type": "code",
        "colab": {},
        "outputId": "6708fe6b-6e0e-4116-97c8-3fa6bd765463"
      },
      "cell_type": "code",
      "source": [
        "labels[100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-0XXsaKW5GQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ngrams_example = vec.transform(['the food was extremely bad!']).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buuh0t8DXW7t",
        "colab_type": "code",
        "colab": {},
        "outputId": "f738786a-432e-4b56-b16e-d9f787f9df20"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "  prediction_ = sess.run(predictions, feed_dict={input_features: ngrams_example.reshape(-1, ngrams_example.shape[1])})\n",
        "  print(prediction_)\n",
        "  print('predicted class : {}'.format(sess.run(tf.argmax(prediction_, 1))))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}