{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-intro-to-tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NKzW-fBI3vAb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkpHsENh36sU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-3_EjYT4DrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cee16647-d0f9-43e9-abc4-c047d11ebcd0"
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y = load_iris().target\n",
        "\n",
        "x[:10], y[:10]\n",
        "\n",
        "np.unique(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "VAarePKb4NpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# batch_size 4\n",
        "input_features = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
        "# batch size 3\n",
        "input_labels = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
        "# [4, 3]\n",
        "weights = tf.Variable(tf.random_normal(shape=[4, 3]))\n",
        "# [3]\n",
        "biases = tf.Variable(tf.random_normal(shape=[3]))\n",
        "\n",
        "# [batch_size, 4] x [4, 3] = [batch_size, 3]\n",
        "# [batch_size, 3] + [3] = [batch_size, 3]\n",
        "\n",
        "linear_model = tf.add(tf.matmul(input_features, weights), biases)\n",
        "\n",
        "\n",
        "# average (wx+b -y) ** 2\n",
        "loss = tf.reduce_mean(tf.square(linear_model - input_labels))\n",
        "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.002).minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M33QsvCv8SVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgQBUzdQ8VnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-X4BJo68brG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, features, labels):\n",
        "  indices = np.arange(start=0, stop=features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices], labels[indices]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQqSJhaR8-e7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "235bd1aa-b4d5-4d29-b448-292bf3759970"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "for epoch in range(10):\n",
        "  for index in range(int(x.shape[0]/batch_size)):\n",
        "    mini_batch_x, mini_batch_y = next_batch(batch_size=batch_size, features=x, labels=y)\n",
        "    from keras.utils import to_categorical\n",
        "    mini_batch_y = to_categorical(mini_batch_y)\n",
        "    _, train_loss = sess.run([train_op, loss], feed_dict={input_features: mini_batch_x, input_labels: mini_batch_y})\n",
        "    \n",
        "  print('Epoch: {0}, loss : {1}'.format(epoch, train_loss))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss : 25.177459716796875\n",
            "Epoch: 1, loss : 6.69122314453125\n",
            "Epoch: 2, loss : 2.7096316814422607\n",
            "Epoch: 3, loss : 1.5903249979019165\n",
            "Epoch: 4, loss : 0.9312933087348938\n",
            "Epoch: 5, loss : 1.1630162000656128\n",
            "Epoch: 6, loss : 1.0952035188674927\n",
            "Epoch: 7, loss : 0.6346256136894226\n",
            "Epoch: 8, loss : 0.9701444506645203\n",
            "Epoch: 9, loss : 0.9863653182983398\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}